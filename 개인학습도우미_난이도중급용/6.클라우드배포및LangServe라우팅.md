# Day 6: 클라우드 배포 및 LangServe 라우팅

## 산출물 1: Docker 컨테이너 구성

### 1. AI 모듈 Dockerfile
```dockerfile
# ai-module/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# 시스템 의존성 설치
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Python 의존성 복사 및 설치
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 애플리케이션 코드 복사
COPY src/ ./src/
COPY data/ ./data/

# 포트 노출
EXPOSE 8000

# 환경변수 설정
ENV PYTHONPATH=/app
ENV LANGCHAIN_TRACING_V2=true
ENV LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
ENV LANGCHAIN_PROJECT="smart-learning-ai"

# 헬스체크
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 서버 시작
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2. Backend Dockerfile
```dockerfile
# backend/Dockerfile
FROM openjdk:17-jdk-slim

WORKDIR /app

# 빌드된 JAR 파일 복사
COPY target/smart-learning-backend-1.0.0.jar app.jar

# 업로드 디렉토리 생성
RUN mkdir -p /app/uploads

# 포트 노출
EXPOSE 8080

# 환경변수
ENV SPRING_PROFILES_ACTIVE=prod
ENV JAVA_OPTS="-Xmx512m -Xms256m"

# 헬스체크
HEALTHCHECK --interval=30s --timeout=30s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8080/actuator/health || exit 1

# 서버 시작
ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

### 3. Frontend Dockerfile
```dockerfile
# frontend/Dockerfile
# 빌드 스테이지
FROM node:18-alpine as builder

WORKDIR /app

# 의존성 설치
COPY package*.json ./
RUN npm ci --only=production

# 앱 빌드
COPY . .
RUN npm run build

# 프로덕션 스테이지
FROM nginx:alpine

# 빌드된 파일 복사
COPY --from=builder /app/build /usr/share/nginx/html

# Nginx 설정 복사
COPY nginx.conf /etc/nginx/nginx.conf

# 포트 노출
EXPOSE 80

# 헬스체크
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost/ || exit 1

CMD ["nginx", "-g", "daemon off;"]
```

### 4. Nginx 설정 (frontend/nginx.conf)
```nginx
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    upstream backend {
        server backend:8080;
    }

    upstream ai-service {
        server ai-service:8000;
    }

    server {
        listen 80;
        server_name localhost;

        # 정적 파일 서빙
        location / {
            root /usr/share/nginx/html;
            index index.html;
            try_files $uri $uri/ /index.html;
        }

        # Backend API 프록시
        location /api/ {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # 파일 업로드를 위한 설정
            client_max_body_size 50M;
            proxy_read_timeout 300s;
            proxy_connect_timeout 75s;
        }

        # AI 서비스 프록시 (LangServe)
        location /ai/ {
            rewrite ^/ai/(.*) /$1 break;
            proxy_pass http://ai-service;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # 스트리밍을 위한 설정
            proxy_buffering off;
            proxy_read_timeout 300s;
            proxy_connect_timeout 75s;
        }

        # WebSocket 지원
        location /ws/ {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
        }

        # LangServe Playground 접근
        location /langserve/ {
            rewrite ^/langserve/(.*) /$1 break;
            proxy_pass http://ai-service;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # 보안 헤더
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;
        add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;
    }
}
```

## 산출물 2: Docker Compose 설정

### docker-compose.yml
```yaml
version: '3.8'

services:
  # 데이터베이스
  database:
    image: mariadb:10.11
    container_name: smart-learning-db
    environment:
      MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD:-root_password}
      MYSQL_DATABASE: ${DB_NAME:-smart_learning_db}
      MYSQL_USER: ${DB_USER:-app_user}
      MYSQL_PASSWORD: ${DB_PASSWORD:-app_password}
    volumes:
      - db_data:/var/lib/mysql
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "3306:3306"
    networks:
      - smart-learning-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10

  # AI 서비스 (LangServe)
  ai-service:
    build:
      context: ./ai-module
      dockerfile: Dockerfile
    container_name: smart-learning-ai
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-false}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT:-smart-learning-ai}
      - DATABASE_URL=mysql://${DB_USER:-app_user}:${DB_PASSWORD:-app_password}@database:3306/${DB_NAME:-smart_learning_db}
    volumes:
      - ai_data:/app/data
      - uploaded_documents:/app/uploaded_documents
    ports:
      - "8000:8000"
    depends_on:
      database:
        condition: service_healthy
    networks:
      - smart-learning-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 백엔드 서비스
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: smart-learning-backend
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - DB_HOST=database
      - DB_PORT=3306
      - DB_NAME=${DB_NAME:-smart_learning_db}
      - DB_USER=${DB_USER:-app_user}
      - DB_PASSWORD=${DB_PASSWORD:-app_password}
      - JWT_SECRET=${JWT_SECRET}
      - AI_SERVICE_URL=http://ai-service:8000
      - FILE_UPLOAD_DIR=/app/uploads
    volumes:
      - backend_uploads:/app/uploads
    ports:
      - "8080:8080"
    depends_on:
      database:
        condition: service_healthy
      ai-service:
        condition: service_healthy
    networks:
      - smart-learning-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 프론트엔드 서비스
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: smart-learning-frontend
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - backend
      - ai-service
    networks:
      - smart-learning-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Redis (캐싱용)
  redis:
    image: redis:7-alpine
    container_name: smart-learning-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-redis_password}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - smart-learning-network
    restart: unless-stopped

  # 모니터링 (Prometheus)
  prometheus:
    image: prom/prometheus:latest
    container_name: smart-learning-prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - smart-learning-network
    restart: unless-stopped

  # 모니터링 대시보드 (Grafana)
  grafana:
    image: grafana/grafana:latest
    container_name: smart-learning-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3000:3000"
    networks:
      - smart-learning-network
    restart: unless-stopped

volumes:
  db_data:
  ai_data:
  backend_uploads:
  uploaded_documents:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  smart-learning-network:
    driver: bridge
```

### docker-compose.prod.yml (프로덕션 오버라이드)
```yaml
version: '3.8'

services:
  ai-service:
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G

  backend:
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  frontend:
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  database:
    volumes:
      - db_data_prod:/var/lib/mysql
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G

volumes:
  db_data_prod:
    external: true
```

## 산출물 3: Kubernetes 배포 설정

### 1. AI 서비스 배포 (k8s/ai-service-deployment.yaml)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-service
  labels:
    app: ai-service
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-service
  template:
    metadata:
      labels:
        app: ai-service
    spec:
      containers:
      - name: ai-service
        image: smart-learning/ai-service:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-secrets
              key: openai-api-key
        - name: LANGCHAIN_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-secrets
              key: langchain-api-key
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: database-url
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - name: ai-data
          mountPath: /app/data
        - name: uploaded-documents
          mountPath: /app/uploaded_documents
      volumes:
      - name: ai-data
        persistentVolumeClaim:
          claimName: ai-data-pvc
      - name: uploaded-documents
        persistentVolumeClaim:
          claimName: uploaded-documents-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: ai-service
spec:
  selector:
    app: ai-service
  ports:
  - protocol: TCP
    port: 8000
    targetPort: 8000
  type: ClusterIP

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ai-data-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: uploaded-documents-pvc
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 50Gi
```

### 2. 백엔드 배포 (k8s/backend-deployment.yaml)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  labels:
    app: backend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: smart-learning/backend:latest
        ports:
        - containerPort: 8080
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: DB_HOST
          value: "database-service"
        - name: DB_NAME
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: db-name
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: db-user
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: db-password
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: jwt-secret
        - name: AI_SERVICE_URL
          value: "http://ai-service:8000"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 90
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
        volumeMounts:
        - name: backend-uploads
          mountPath: /app/uploads
      volumes:
      - name: backend-uploads
        persistentVolumeClaim:
          claimName: backend-uploads-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  selector:
    app: backend
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 8080
  type: ClusterIP

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backend-uploads-pvc
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 20Gi
```

### 3. 인그레스 설정 (k8s/ingress.yaml)
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: smart-learning-ingress
  annotations:
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - smartlearning.example.com
    secretName: smartlearning-tls
  rules:
  - host: smartlearning.example.com
    http:
      paths:
      # 프론트엔드
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 80
      
      # 백엔드 API
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 8080
      
      # AI 서비스 (LangServe)
      - path: /ai
        pathType: Prefix
        backend:
          service:
            name: ai-service
            port:
              number: 8000
      
      # LangServe Playground
      - path: /langserve
        pathType: Prefix
        backend:
          service:
            name: ai-service
            port:
              number: 8000
```

## 산출물 4: CI/CD 파이프라인

### GitHub Actions (.github/workflows/deploy.yml)
```yaml
name: Deploy to Production

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: smart-learning

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v4
    
    # Backend 테스트
    - name: Set up JDK 17
      uses: actions/setup-java@v3
      with:
        java-version: '17'
        distribution: 'temurin'
    
    - name: Cache Maven packages
      uses: actions/cache@v3
      with:
        path: ~/.m2
        key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
    
    - name: Run backend tests
      working-directory: ./backend
      run: mvn clean test
    
    # Frontend 테스트
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install dependencies
      working-directory: ./frontend
      run: npm ci
    
    - name: Run frontend tests
      working-directory: ./frontend
      run: npm test -- --coverage --watchAll=false
    
    # AI 모듈 테스트
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install AI dependencies
      working-directory: ./ai-module
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run AI tests
      working-directory: ./ai-module
      run: pytest tests/ -v

  build-and-push:
    needs: test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        service: [ai-service, backend, frontend]
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Login to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.repository }}/${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
    
    - name: Build and push
      uses: docker/build-push-action@v5
      with:
        context: ./${{ matrix.service == 'ai-service' && 'ai-module' || matrix.service }}
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy:
    needs: build-and-push
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Setup kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'
    
    - name: Setup Helm
      uses: azure/setup-helm@v3
      with:
        version: 'v3.12.0'
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-2
    
    - name: Update kubeconfig
      run: aws eks update-kubeconfig --name smart-learning-cluster
    
    - name: Deploy to Kubernetes
      run: |
        # 이미지 태그 업데이트
        sed -i "s|image: smart-learning/ai-service:.*|image: ${{ env.REGISTRY }}/${{ github.repository }}/ai-service:${{ github.sha }}|" k8s/ai-service-deployment.yaml
        sed -i "s|image: smart-learning/backend:.*|image: ${{ env.REGISTRY }}/${{ github.repository }}/backend:${{ github.sha }}|" k8s/backend-deployment.yaml
        sed -i "s|image: smart-learning/frontend:.*|image: ${{ env.REGISTRY }}/${{ github.repository }}/frontend:${{ github.sha }}|" k8s/frontend-deployment.yaml
        
        # 배포 실행
        kubectl apply -f k8s/
        
        # 배포 상태 확인
        kubectl rollout status deployment/ai-service --timeout=300s
        kubectl rollout status deployment/backend --timeout=300s
        kubectl rollout status deployment/frontend --timeout=300s
    
    - name: Verify deployment
      run: |
        kubectl get pods -l app=ai-service
        kubectl get pods -l app=backend
        kubectl get pods -l app=frontend
        kubectl get ingress
```

## 산출물 5: AWS/GCP 배포 스크립트

### AWS EKS 배포 (deployment/aws/deploy.sh)
```bash
#!/bin/bash

set -e

# 색상 정의
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# 로그 함수
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# 환경 변수 확인
check_env() {
    local required_vars=(
        "AWS_REGION"
        "CLUSTER_NAME"
        "OPENAI_API_KEY"
        "DB_PASSWORD"
        "JWT_SECRET"
    )
    
    for var in "${required_vars[@]}"; do
        if [ -z "${!var}" ]; then
            log_error "Required environment variable $var is not set"
            exit 1
        fi
    done
}

# EKS 클러스터 생성
create_eks_cluster() {
    log_info "Creating EKS cluster: $CLUSTER_NAME"
    
    eksctl create cluster \
        --name $CLUSTER_NAME \
        --region $AWS_REGION \
        --node-type m5.large \
        --nodes 3 \
        --nodes-min 1 \
        --nodes-max 5 \
        --managed \
        --with-oidc \
        --ssh-access \
        --ssh-public-key eks-key \
        --full-ecr-access
    
    log_info "EKS cluster created successfully"
}

# AWS Load Balancer Controller 설치
install_alb_controller() {
    log_info "Installing AWS Load Balancer Controller"
    
    # OIDC 연결
    eksctl utils associate-iam-oidc-provider --cluster $CLUSTER_NAME --approve
    
    # IAM 역할 생성
    eksctl create iamserviceaccount \
        --cluster=$CLUSTER_NAME \
        --namespace=kube-system \
        --name=aws-load-balancer-controller \
        --role-name AmazonEKSLoadBalancerControllerRole \
        --attach-policy-arn=arn:aws:iam::$AWS_ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy \
        --approve
    
    # Helm으로 설치
    helm repo add eks https://aws.github.io/eks-charts
    helm repo update
    
    helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
        -n kube-system \
        --set clusterName=$CLUSTER_NAME \
        --set serviceAccount.create=false \
        --set serviceAccount.name=aws-load-balancer-controller
}

# RDS 인스턴스 생성
create_rds() {
    log_info "Creating RDS instance"
    
    aws rds create-db-instance \
        --db-instance-identifier smart-learning-db \
        --db-instance-class db.t3.micro \
        --engine mariadb \
        --master-username admin \
        --master-user-password $DB_PASSWORD \
        --allocated-storage 20 \
        --vpc-security-group-ids $DB_SECURITY_GROUP \
        --db-subnet-group-name $DB_SUBNET_GROUP \
        --backup-retention-period 7 \
        --storage-encrypted \
        --multi-az false
    
    log_info "Waiting for RDS instance to be available..."
    aws rds wait db-instance-available --db-instance-identifier smart-learning-db
}

# Kubernetes 시크릿 생성
create_secrets() {
    log_info "Creating Kubernetes secrets"
    
    # AI 서비스 시크릿
    kubectl create secret generic ai-secrets \
        --from-literal=openai-api-key=$OPENAI_API_KEY \
        --from-literal=langchain-api-key=$LANGCHAIN_API_KEY \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # 데이터베이스 시크릿
    kubectl create secret generic db-secrets \
        --from-literal=db-name=smart_learning_db \
        --from-literal=db-user=admin \
        --from-literal=db-password=$DB_PASSWORD \
        --from-literal=database-url="mysql://admin:$DB_PASSWORD@$RDS_ENDPOINT:3306/smart_learning_db" \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # 애플리케이션 시크릿
    kubectl create secret generic app-secrets \
        --from-literal=jwt-secret=$JWT_SECRET \
        --dry-run=client -o yaml | kubectl apply -f -
}

# 스토리지 클래스 생성
create_storage() {
    log_info "Creating storage classes"
    
    cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gp3-retain
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  fsType: ext4
reclaimPolicy: Retain
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
EOF
}

# 애플리케이션 배포
deploy_application() {
    log_info "Deploying application"
    
    # ConfigMap 생성
    kubectl create configmap app-config \
        --from-literal=spring.profiles.active=prod \
        --from-literal=ai.service.base-url=http://ai-service:8000 \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # 애플리케이션 배포
    kubectl apply -f k8s/
    
    # 배포 상태 확인
    log_info "Waiting for deployments to be ready..."
    kubectl wait --for=condition=available --timeout=600s deployment/ai-service
    kubectl wait --for=condition=available --timeout=600s deployment/backend
    kubectl wait --for=condition=available --timeout=600s deployment/frontend
}

# 모니터링 설치
install_monitoring() {
    log_info "Installing monitoring stack"
    
    # Prometheus Operator 설치
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    helm repo update
    
    helm install prometheus prometheus-community/kube-prometheus-stack \
        --namespace monitoring \
        --create-namespace \
        --set grafana.adminPassword=$GRAFANA_PASSWORD
    
    log_info "Monitoring stack installed"
}

# 메인 함수
main() {
    log_info "Starting AWS EKS deployment"
    
    check_env
    
    # AWS 계정 ID 가져오기
    export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
    
    # RDS 엔드포인트 가져오기 (이미 생성된 경우)
    export RDS_ENDPOINT=$(aws rds describe-db-instances \
        --db-instance-identifier smart-learning-db \
        --query 'DBInstances[0].Endpoint.Address' \
        --output text 2>/dev/null || echo "")
    
    # 클러스터가 존재하지 않으면 생성
    if ! eksctl get cluster --name $CLUSTER_NAME &>/dev/null; then
        create_eks_cluster
        install_alb_controller
    fi
    
    # kubeconfig 업데이트
    aws eks update-kubeconfig --name $CLUSTER_NAME --region $AWS_REGION
    
    # RDS 인스턴스가 존재하지 않으면 생성
    if [ -z "$RDS_ENDPOINT" ]; then
        create_rds
        export RDS_ENDPOINT=$(aws rds describe-db-instances \
            --db-instance-identifier smart-learning-db \
            --query 'DBInstances[0].Endpoint.Address' \
            --output text)
    fi
    
    create_storage
    create_secrets
    deploy_application
    install_monitoring
    
    # 결과 출력
    log_info "Deployment completed successfully!"
    log_info "Application URL: https://$(kubectl get ingress smart-learning-ingress -o jsonpath='{.spec.rules[0].host}')"
    log_info "Grafana URL: http://$(kubectl get svc prometheus-grafana -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'):3000"
    
    kubectl get pods --all-namespaces
}

# 스크립트 실행
main "$@"
```

### GCP GKE 배포 (deployment/gcp/deploy.sh)
```bash
#!/bin/bash

set -e

# 색상 정의
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# 환경 변수 확인
check_env() {
    local required_vars=(
        "PROJECT_ID"
        "CLUSTER_NAME"
        "ZONE"
        "OPENAI_API_KEY"
        "DB_PASSWORD"
        "JWT_SECRET"
    )
    
    for var in "${required_vars[@]}"; do
        if [ -z "${!var}" ]; then
            log_error "Required environment variable $var is not set"
            exit 1
        fi
    done
}

# GKE 클러스터 생성
create_gke_cluster() {
    log_info "Creating GKE cluster: $CLUSTER_NAME"
    
    gcloud container clusters create $CLUSTER_NAME \
        --zone $ZONE \
        --machine-type e2-standard-2 \
        --num-nodes 3 \
        --enable-autoscaling \
        --min-nodes 1 \
        --max-nodes 5 \
        --enable-autorepair \
        --enable-autoupgrade \
        --disk-size 50 \
        --disk-type pd-ssd \
        --enable-ip-alias \
        --enable-network-policy \
        --addons HorizontalPodAutoscaling,HttpLoadBalancing \
        --workload-pool=$PROJECT_ID.svc.id.goog
    
    log_info "GKE cluster created successfully"
}

# Cloud SQL 인스턴스 생성
create_cloud_sql() {
    log_info "Creating Cloud SQL instance"
    
    gcloud sql instances create smart-learning-db \
        --database-version=MYSQL_8_0 \
        --tier=db-f1-micro \
        --region=$REGION \
        --storage-size=20GB \
        --storage-type=SSD \
        --backup-start-time=03:00 \
        --enable-bin-log \
        --maintenance-window-day=SUN \
        --maintenance-window-hour=04 \
        --root-password=$DB_PASSWORD
    
    # 데이터베이스 생성
    gcloud sql databases create smart_learning_db --instance=smart-learning-db
    
    # 사용자 생성
    gcloud sql users create app_user \
        --instance=smart-learning-db \
        --password=$DB_PASSWORD
    
    log_info "Cloud SQL instance created successfully"
}

# Google Container Registry 설정
setup_gcr() {
    log_info "Configuring Google Container Registry"
    
    gcloud auth configure-docker
    
    # 도커 이미지 빌드 및 푸시
    for service in ai-service backend frontend; do
        log_info "Building and pushing $service image"
        
        if [ "$service" = "ai-service" ]; then
            docker build -t gcr.io/$PROJECT_ID/$service:latest ./ai-module
        else
            docker build -t gcr.io/$PROJECT_ID/$service:latest ./$service
        fi
        
        docker push gcr.io/$PROJECT_ID/$service:latest
    done
}

# 시크릿 생성
create_gcp_secrets() {
    log_info "Creating Kubernetes secrets"
    
    # 클러스터 자격 증명 가져오기
    gcloud container clusters get-credentials $CLUSTER_NAME --zone $ZONE
    
    # Cloud SQL 프록시를 위한 서비스 계정 생성
    gcloud iam service-accounts create cloudsql-proxy \
        --display-name="Cloud SQL Proxy Service Account"
    
    gcloud projects add-iam-policy-binding $PROJECT_ID \
        --member="serviceAccount:cloudsql-proxy@$PROJECT_ID.iam.gserviceaccount.com" \
        --role="roles/cloudsql.client"
    
    gcloud iam service-accounts keys create key.json \
        --iam-account=cloudsql-proxy@$PROJECT_ID.iam.gserviceaccount.com
    
    kubectl create secret generic cloudsql-instance-credentials \
        --from-file=credentials.json=key.json
    
    # 애플리케이션 시크릿
    kubectl create secret generic ai-secrets \
        --from-literal=openai-api-key=$OPENAI_API_KEY \
        --from-literal=langchain-api-key=$LANGCHAIN_API_KEY \
        --dry-run=client -o yaml | kubectl apply -f -
    
    kubectl create secret generic app-secrets \
        --from-literal=jwt-secret=$JWT_SECRET \
        --from-literal=db-password=$DB_PASSWORD \
        --dry-run=client -o yaml | kubectl apply -f -
    
    rm key.json
}

# GCP 배포 매니페스트 생성
create_gcp_manifests() {
    log_info "Creating GCP-specific manifests"
    
    # Cloud SQL 프록시 배포
    cat <<EOF > k8s/cloudsql-proxy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cloudsql-proxy
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cloudsql-proxy
  template:
    metadata:
      labels:
        app: cloudsql-proxy
    spec:
      containers:
      - name: cloudsql-proxy
        image: gcr.io/cloudsql-docker/gce-proxy:1.33.7
        command:
        - "/cloud_sql_proxy"
        - "-instances=$PROJECT_ID:$REGION:smart-learning-db=tcp:0.0.0.0:3306"
        - "-credential_file=/secrets/cloudsql/credentials.json"
        ports:
        - containerPort: 3306
        volumeMounts:
        - name: cloudsql-instance-credentials
          mountPath: /secrets/cloudsql
          readOnly: true
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      volumes:
      - name: cloudsql-instance-credentials
        secret:
          secretName: cloudsql-instance-credentials
---
apiVersion: v1
kind: Service
metadata:
  name: cloudsql-proxy-service
spec:
  selector:
    app: cloudsql-proxy
  ports:
  - port: 3306
    targetPort: 3306
  type: ClusterIP
EOF

    # GCP Load Balancer를 위한 인그레스 수정
    cat <<EOF > k8s/gcp-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: smart-learning-ingress
  annotations:
    kubernetes.io/ingress.class: "gce"
    kubernetes.io/ingress.global-static-ip-name: "smart-learning-ip"
    networking.gke.io/managed-certificates: "smart-learning-ssl-cert"
    kubernetes.io/ingress.allow-http: "false"
spec:
  rules:
  - host: smartlearning.example.com
    http:
      paths:
      - path: /*
        pathType: ImplementationSpecific
        backend:
          service:
            name: frontend-service
            port:
              number: 80
      - path: /api/*
        pathType: ImplementationSpecific
        backend:
          service:
            name: backend-service
            port:
              number: 8080
      - path: /ai/*
        pathType: ImplementationSpecific
        backend:
          service:
            name: ai-service
            port:
              number: 8000
---
apiVersion: networking.gke.io/v1
kind: ManagedCertificate
metadata:
  name: smart-learning-ssl-cert
spec:
  domains:
  - smartlearning.example.com
EOF
}

# 정적 IP 생성
create_static_ip() {
    log_info "Creating static IP address"
    
    gcloud compute addresses create smart-learning-ip --global
    
    local ip_address=$(gcloud compute addresses describe smart-learning-ip --global --format="value(address)")
    log_info "Static IP created: $ip_address"
    log_warn "Please update your DNS to point smartlearning.example.com to $ip_address"
}

# 애플리케이션 배포
deploy_gcp_application() {
    log_info "Deploying application to GKE"
    
    # 이미지 경로를 GCR로 업데이트
    sed -i "s|smart-learning/ai-service:latest|gcr.io/$PROJECT_ID/ai-service:latest|g" k8s/ai-service-deployment.yaml
    sed -i "s|smart-learning/backend:latest|gcr.io/$PROJECT_ID/backend:latest|g" k8s/backend-deployment.yaml
    sed -i "s|smart-learning/frontend:latest|gcr.io/$PROJECT_ID/frontend:latest|g" k8s/frontend-deployment.yaml
    
    # 데이터베이스 호스트를 Cloud SQL 프록시로 변경
    sed -i "s|database-service|cloudsql-proxy-service|g" k8s/backend-deployment.yaml
    
    # 배포 실행
    kubectl apply -f k8s/
    
    # 배포 상태 확인
    log_info "Waiting for deployments to be ready..."
    kubectl wait --for=condition=available --timeout=600s deployment/cloudsql-proxy
    kubectl wait --for=condition=available --timeout=600s deployment/ai-service
    kubectl wait --for=condition=available --timeout=600s deployment/backend
    kubectl wait --for=condition=available --timeout=600s deployment/frontend
}

# 모니터링 설정
setup_gcp_monitoring() {
    log_info "Setting up GCP monitoring"
    
    # Google Cloud Monitoring 에이전트 설치
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    helm repo update
    
    helm install prometheus prometheus-community/kube-prometheus-stack \
        --namespace monitoring \
        --create-namespace \
        --set grafana.adminPassword=$GRAFANA_PASSWORD \
        --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false
    
    # Google Cloud Logging 설정
    kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded.yaml
}

# 메인 함수
main() {
    log_info "Starting GCP GKE deployment"
    
    check_env
    
    # 기본값 설정
    export REGION=${REGION:-us-central1}
    
    # 프로젝트 설정
    gcloud config set project $PROJECT_ID
    
    # 필요한 API 활성화
    gcloud services enable container.googleapis.com
    gcloud services enable sqladmin.googleapis.com
    gcloud services enable containerregistry.googleapis.com
    
    # 클러스터가 존재하지 않으면 생성
    if ! gcloud container clusters describe $CLUSTER_NAME --zone $ZONE &>/dev/null; then
        create_gke_cluster
    fi
    
    # Cloud SQL 인스턴스가 존재하지 않으면 생성
    if ! gcloud sql instances describe smart-learning-db &>/dev/null; then
        create_cloud_sql
    fi
    
    # 정적 IP가 존재하지 않으면 생성
    if ! gcloud compute addresses describe smart-learning-ip --global &>/dev/null; then
        create_static_ip
    fi
    
    setup_gcr
    create_gcp_secrets
    create_gcp_manifests
    deploy_gcp_application
    setup_gcp_monitoring
    
    # 결과 출력
    log_info "Deployment completed successfully!"
    local ip_address=$(gcloud compute addresses describe smart-learning-ip --global --format="value(address)")
    log_info "Application will be available at: https://smartlearning.example.com (IP: $ip_address)"
    log_info "Grafana URL: http://$(kubectl get svc prometheus-grafana -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].ip}'):3000"
    
    kubectl get pods --all-namespaces
}

# 스크립트 실행
main "$@"
```

## 산출물 6: 환경별 설정 파일

### 개발 환경 (.env.development)
```bash
# 개발 환경 설정
NODE_ENV=development
REACT_APP_API_BASE_URL=http://localhost:8080
REACT_APP_AI_SERVICE_URL=http://localhost:8000

# Backend 설정
SPRING_PROFILES_ACTIVE=dev
DB_HOST=localhost
DB_PORT=3306
DB_NAME=smart_learning_dev
DB_USER=dev_user
DB_PASSWORD=dev_password
JWT_SECRET=dev_jwt_secret_key_that_is_at_least_256_bits_long

# AI 서비스 설정
AI_SERVICE_URL=http://localhost:8000
OPENAI_API_KEY=your_openai_api_key_here
LANGCHAIN_API_KEY=your_langchain_api_key_here
LANGCHAIN_TRACING_V2=false

# 파일 업로드
FILE_UPLOAD_DIR=./uploads
MAX_FILE_SIZE=50MB

# Redis
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=redis_dev_password
```

### 스테이징 환경 (.env.staging)
```bash
# 스테이징 환경 설정
NODE_ENV=staging
REACT_APP_API_BASE_URL=https://staging-api.smartlearning.com
REACT_APP_AI_SERVICE_URL=https://staging-ai.smartlearning.com

# Backend 설정
SPRING_PROFILES_ACTIVE=staging
DB_HOST=staging-db.cluster-xxxxx.ap-northeast-2.rds.amazonaws.com
DB_PORT=3306
DB_NAME=smart_learning_staging
DB_USER=staging_user
DB_PASSWORD=${DB_PASSWORD}
JWT_SECRET=${JWT_SECRET}

# AI 서비스 설정
AI_SERVICE_URL=http://ai-service:8000
OPENAI_API_KEY=${OPENAI_API_KEY}
LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=smart-learning-staging

# 스토리지
FILE_UPLOAD_DIR=/app/uploads
AWS_S3_BUCKET=smart-learning-staging-uploads
AWS_REGION=ap-northeast-2

# 모니터링
GRAFANA_PASSWORD=${GRAFANA_PASSWORD}
```

### 프로덕션 환경 (.env.production)
```bash
# 프로덕션 환경 설정
NODE_ENV=production
REACT_APP_API_BASE_URL=https://api.smartlearning.com
REACT_APP_AI_SERVICE_URL=https://ai.smartlearning.com

# Backend 설정
SPRING_PROFILES_ACTIVE=prod
DB_HOST=prod-db.cluster-xxxxx.ap-northeast-2.rds.amazonaws.com
DB_PORT=3306
DB_NAME=smart_learning_prod
DB_USER=prod_user
DB_PASSWORD=${DB_PASSWORD}
JWT_SECRET=${JWT_SECRET}

# AI 서비스 설정
AI_SERVICE_URL=http://ai-service:8000
OPENAI_API_KEY=${OPENAI_API_KEY}
LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=smart-learning-production

# 고성능 설정
JAVA_OPTS=-Xmx2g -Xms1g -XX:+UseG1GC
PYTHON_WORKERS=4
REDIS_MAX_CONNECTIONS=100

# 보안
CORS_ALLOWED_ORIGINS=https://smartlearning.com,https://www.smartlearning.com
SSL_CERTIFICATE_PATH=/etc/ssl/certs/smartlearning.crt
SSL_PRIVATE_KEY_PATH=/etc/ssl/private/smartlearning.key

# 모니터링 및 로깅
LOG_LEVEL=INFO
SENTRY_DSN=${SENTRY_DSN}
GRAFANA_PASSWORD=${GRAFANA_PASSWORD}
```

## 산출물 7: 모니터링 및 헬스체크

### monitoring/prometheus.yml
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "smart_learning_rules.yml"

scrape_configs:
  # Kubernetes API Server
  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
    - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
      action: keep
      regex: default;kubernetes;https

  # Smart Learning Backend
  - job_name: 'smart-learning-backend'
    kubernetes_sd_configs:
    - role: endpoints
    relabel_configs:
    - source_labels: [__meta_kubernetes_service_name]
      action: keep
      regex: backend-service
    - source_labels: [__meta_kubernetes_endpoint_port_name]
      action: keep
      regex: http

  # Smart Learning AI Service
  - job_name: 'smart-learning-ai'
    kubernetes_sd_configs:
    - role: endpoints
    relabel_configs:
    - source_labels: [__meta_kubernetes_service_name]
      action: keep
      regex: ai-service
    - source_labels: [__meta_kubernetes_endpoint_port_name]
      action: keep
      regex: http

  # Node Exporter
  - job_name: 'node-exporter'
    kubernetes_sd_configs:
    - role: endpoints
    relabel_configs:
    - source_labels: [__meta_kubernetes_service_name]
      action: keep
      regex: node-exporter

alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager:9093
```

### monitoring/smart_learning_rules.yml
```yaml
groups:
- name: smart_learning.rules
  rules:
  
  # 응답 시간 알림
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time detected"
      description: "95th percentile response time is {{ $value }}s"

  # AI 서비스 다운 알림
  - alert: AIServiceDown
    expr: up{job="smart-learning-ai"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "AI Service is down"
      description: "AI Service has been down for more than 1 minute"

  # 백엔드 서비스 다운 알림
  - alert: BackendServiceDown
    expr: up{job="smart-learning-backend"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Backend Service is down"
      description: "Backend Service has been down for more than 1 minute"

  # 높은 CPU 사용률 알림
  - alert: HighCPUUsage
    expr: rate(cpu_usage_seconds_total[5m]) > 0.8
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is {{ $value | humanizePercentage }}"

  # 높은 메모리 사용률 알림
  - alert: HighMemoryUsage
    expr: memory_usage_bytes / memory_limit_bytes > 0.9
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is {{ $value | humanizePercentage }}"

  # 데이터베이스 연결 실패 알림
  - alert: DatabaseConnectionFailure
    expr: database_connections_active / database_connections_max > 0.8
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Database connection pool near limit"
      description: "Database connections: {{ $value | humanizePercentage }} of max"

  # 디스크 사용률 알림
  - alert: HighDiskUsage
    expr: (1 - disk_free_bytes / disk_total_bytes) > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High disk usage detected"
      description: "Disk usage is {{ $value | humanizePercentage }}"
```

### 헬스체크 엔드포인트 (backend/src/main/java/com/smartlearning/controller/HealthController.java)
```java
@RestController
@RequestMapping("/actuator")
@Slf4j
public class HealthController {
    
    @Autowired
    private DataSource dataSource;
    
    @Autowired
    private AIIntegrationService aiIntegrationService;
    
    @GetMapping("/health")
    public ResponseEntity<Map<String, Object>> health() {
        Map<String, Object> health = new HashMap<>();
        Map<String, Object> components = new HashMap<>();
        
        boolean isHealthy = true;
        
        // 데이터베이스 상태 확인
        try {
            try (Connection conn = dataSource.getConnection()) {
                components.put("database", Map.of(
                    "status", "UP",
                    "details", Map.of("connection", "active")
                ));
            }
        } catch (Exception e) {
            isHealthy = false;
            components.put("database", Map.of(
                "status", "DOWN",
                "details", Map.of("error", e.getMessage())
            ));
        }
        
        // AI 서비스 상태 확인
        try {
            // AI 서비스 헬스체크 호출
            String aiHealth = checkAIServiceHealth();
            components.put("ai-service", Map.of(
                "status", "UP",
                "details", Map.of("response", aiHealth)
            ));
        } catch (Exception e) {
            isHealthy = false;
            components.put("ai-service", Map.of(
                "status", "DOWN",
                "details", Map.of("error", e.getMessage())
            ));
        }
        
        // 시스템 메트릭
        Runtime runtime = Runtime.getRuntime();
        long maxMemory = runtime.maxMemory();
        long totalMemory = runtime.totalMemory();
        long freeMemory = runtime.freeMemory();
        long usedMemory = totalMemory - freeMemory;
        
        components.put("system", Map.of(
            "status", "UP",
            "details", Map.of(
                "memory", Map.of(
                    "used", usedMemory,
                    "free", freeMemory,
                    "total", totalMemory,
                    "max", maxMemory,
                    "usage_percentage", (double) usedMemory / maxMemory * 100
                ),
                "processors", runtime.availableProcessors(),
                "uptime", ManagementFactory.getRuntimeMXBean().getUptime()
            )
        ));
        
        health.put("status", isHealthy ? "UP" : "DOWN");
        health.put("components", components);
        health.put("timestamp", Instant.now());
        
        return ResponseEntity
            .status(isHealthy ? HttpStatus.OK : HttpStatus.SERVICE_UNAVAILABLE)
            .body(health);
    }
    
    @GetMapping("/metrics")
    public ResponseEntity<Map<String, Object>> metrics() {
        Map<String, Object> metrics = new HashMap<>();
        
        // JVM 메트릭
        MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean();
        MemoryUsage heapUsage = memoryBean.getHeapMemoryUsage();
        
        metrics.put("jvm_memory_used_bytes", heapUsage.getUsed());
        metrics.put("jvm_memory_max_bytes", heapUsage.getMax());
        metrics.put("jvm_memory_committed_bytes", heapUsage.getCommitted());
        
        // 스레드 메트릭
        ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();
        metrics.put("jvm_threads_current", threadBean.getThreadCount());
        metrics.put("jvm_threads_peak", threadBean.getPeakThreadCount());
        
        // 가비지 컬렉션 메트릭
        for (GarbageCollectorMXBean gcBean : ManagementFactory.getGarbageCollectorMXBeans()) {
            String name = gcBean.getName().replaceAll(" ", "_").toLowerCase();
            metrics.put("jvm_gc_collection_seconds_total_" + name, gcBean.getCollectionTime() / 1000.0);
            metrics.put("jvm_gc_collection_total_" + name, gcBean.getCollectionCount());
        }
        
        return ResponseEntity.ok(metrics);
    }
    
    private String checkAIServiceHealth() {
        // AI 서비스 헬스체크 로직
        try {
            RestTemplate restTemplate = new RestTemplate();
            return restTemplate.getForObject("http://ai-service:8000/health", String.class);
        } catch (Exception e) {
            throw new RuntimeException("AI service health check failed", e);
        }
    }
}
```

## 주요 배포 포인트

###  **LangServe 라우팅 최적화**
- **Nginx 프록시**: AI 서비스로의 효율적인 라우팅
- **포트 분리**: Frontend(80), Backend(8080), AI(8000)
- **Playground 접근**: `/langserve` 경로로 개발 도구 접근

###  **클라우드 네이티브 설계**
- **컨테이너 오케스트레이션**: Kubernetes 기반 확장성
- **마이크로서비스**: 각 서비스별 독립적 스케일링
- **서비스 메시**: 내부 통신 최적화

###  **모니터링 및 관찰가능성**
- **Prometheus/Grafana**: 실시간 메트릭 수집
- **분산 추적**: LangChain 요청 추적
- **로그 집계**: 중앙화된 로그 관리

###  **보안 및 성능**
- **SSL/TLS**: 전체 통신 암호화
- **시크릿 관리**: Kubernetes 시크릿 활용
- **자동 스케일링**: 트래픽 기반 확장



